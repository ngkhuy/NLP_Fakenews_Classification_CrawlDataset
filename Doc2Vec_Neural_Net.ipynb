{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from gensim) (1.25.2)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from gensim) (1.11.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from smart-open>=1.8.1->gensim) (1.14.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\program files\\python311\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: underthesea in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (6.8.4)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from underthesea) (8.1.7)\n",
      "Requirement already satisfied: python-crfsuite>=0.9.6 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from underthesea) (0.9.11)\n",
      "Requirement already satisfied: nltk in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from underthesea) (3.9.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from underthesea) (4.66.2)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from underthesea) (2.31.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from underthesea) (1.3.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from underthesea) (1.3.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from underthesea) (6.0.1)\n",
      "Requirement already satisfied: underthesea-core==1.0.4 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from underthesea) (1.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from Click>=6.0->underthesea) (0.4.6)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from nltk->underthesea) (2024.5.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from requests->underthesea) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from requests->underthesea) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from requests->underthesea) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from requests->underthesea) (2023.7.22)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn->underthesea) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn->underthesea) (1.11.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn->underthesea) (3.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\program files\\python311\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install underthesea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>sub_title</th>\n",
       "      <th>Content</th>\n",
       "      <th>Tag</th>\n",
       "      <th>tokenized_title</th>\n",
       "      <th>tokenized_sub_title</th>\n",
       "      <th>tokenized_content</th>\n",
       "      <th>combine_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tại sao phụ nữ đòi bình đẳng nhưng bắt đàn ông...</td>\n",
       "      <td>\"Quy tắc số 1\" của Minh An khi hẹn hò là đàn ô...</td>\n",
       "      <td>\"Làm gì có bình đẳng thực sự. Phụ nữ vẫn chịu ...</td>\n",
       "      <td>1</td>\n",
       "      <td>tại_sao phụ_nữ đòi bình_đẳng nhưng bắt đàn_ông...</td>\n",
       "      <td>quy_tắc số 1 của minh_an khi hẹn_hò là đàn_ông...</td>\n",
       "      <td>làm gì có bình_đẳng thực_sự phụ_nữ vẫn chịu nh...</td>\n",
       "      <td>tại_sao phụ_nữ đòi bình_đẳng nhưng bắt đàn_ông...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Capello: 'Guardiola mất nhiều Champions League...</td>\n",
       "      <td>AnhTheo cựu HLV Fabio Capello, Pep Guardiola p...</td>\n",
       "      <td>\"Bạn có biết tôi không thích điều gì ở Guardio...</td>\n",
       "      <td>1</td>\n",
       "      <td>capello guardiola mất nhiều champions_league v...</td>\n",
       "      <td>anhtheo cựu hlv fabio capello pep guardiola ph...</td>\n",
       "      <td>bạn có biết tôi không thích điều gì ở guardiol...</td>\n",
       "      <td>capello guardiola mất nhiều champions_league v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xe ga sang xịn của ông lớn Trung Quốc: Thiết k...</td>\n",
       "      <td>Không chỉ sở hữu mức giá ngang ngửa Honda Wave...</td>\n",
       "      <td>Paifang Motorcycle (PFMoto) – thương hiệu xe m...</td>\n",
       "      <td>0</td>\n",
       "      <td>xe ga sang xịn của ông lớn trung_quốc thiết_kế...</td>\n",
       "      <td>không_chỉ sở_hữu mức giá ngang ngửa honda wave...</td>\n",
       "      <td>paifang motorcycle pfmoto thương_hiệu xe_máy đ...</td>\n",
       "      <td>xe ga sang xịn của ông lớn trung_quốc thiết_kế...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Không gian mở phong cách Hàn tại Gem Park</td>\n",
       "      <td>Hải PhòngToàn bộ khu tiện ích tại Gem Park đượ...</td>\n",
       "      <td>Hướng đến việc nâng cao trải nghiệm sống của c...</td>\n",
       "      <td>1</td>\n",
       "      <td>không_gian mở phong_cách hàn tại gem park</td>\n",
       "      <td>hải_phòngtoàn bộ khu tiện_ích tại gem park đượ...</td>\n",
       "      <td>hướng đến việc nâng cao trải_nghiệm sống của c...</td>\n",
       "      <td>không_gian mở phong_cách hàn tại gem park hải_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21 thanh niên hỗn chiến trong đêm</td>\n",
       "      <td>Nghệ AnHai nhóm thanh niên ở huyện Đô Lương do...</td>\n",
       "      <td>Ngày 11/3, Phòng Cảnh sát hình sự (Công an tỉn...</td>\n",
       "      <td>1</td>\n",
       "      <td>21 thanh_niên hỗn_chiến trong đêm</td>\n",
       "      <td>nghệ anhai nhóm thanh_niên ở huyện đô_lương do...</td>\n",
       "      <td>ngày 11 3 phòng cảnh_sát hình_sự công_an tỉnh ...</td>\n",
       "      <td>21 thanh_niên hỗn_chiến trong đêm nghệ anhai n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Tại sao phụ nữ đòi bình đẳng nhưng bắt đàn ông...   \n",
       "1  Capello: 'Guardiola mất nhiều Champions League...   \n",
       "2  Xe ga sang xịn của ông lớn Trung Quốc: Thiết k...   \n",
       "3          Không gian mở phong cách Hàn tại Gem Park   \n",
       "4                  21 thanh niên hỗn chiến trong đêm   \n",
       "\n",
       "                                           sub_title  \\\n",
       "0  \"Quy tắc số 1\" của Minh An khi hẹn hò là đàn ô...   \n",
       "1  AnhTheo cựu HLV Fabio Capello, Pep Guardiola p...   \n",
       "2  Không chỉ sở hữu mức giá ngang ngửa Honda Wave...   \n",
       "3  Hải PhòngToàn bộ khu tiện ích tại Gem Park đượ...   \n",
       "4  Nghệ AnHai nhóm thanh niên ở huyện Đô Lương do...   \n",
       "\n",
       "                                             Content  Tag  \\\n",
       "0  \"Làm gì có bình đẳng thực sự. Phụ nữ vẫn chịu ...    1   \n",
       "1  \"Bạn có biết tôi không thích điều gì ở Guardio...    1   \n",
       "2  Paifang Motorcycle (PFMoto) – thương hiệu xe m...    0   \n",
       "3  Hướng đến việc nâng cao trải nghiệm sống của c...    1   \n",
       "4  Ngày 11/3, Phòng Cảnh sát hình sự (Công an tỉn...    1   \n",
       "\n",
       "                                     tokenized_title  \\\n",
       "0  tại_sao phụ_nữ đòi bình_đẳng nhưng bắt đàn_ông...   \n",
       "1  capello guardiola mất nhiều champions_league v...   \n",
       "2  xe ga sang xịn của ông lớn trung_quốc thiết_kế...   \n",
       "3          không_gian mở phong_cách hàn tại gem park   \n",
       "4                  21 thanh_niên hỗn_chiến trong đêm   \n",
       "\n",
       "                                 tokenized_sub_title  \\\n",
       "0  quy_tắc số 1 của minh_an khi hẹn_hò là đàn_ông...   \n",
       "1  anhtheo cựu hlv fabio capello pep guardiola ph...   \n",
       "2  không_chỉ sở_hữu mức giá ngang ngửa honda wave...   \n",
       "3  hải_phòngtoàn bộ khu tiện_ích tại gem park đượ...   \n",
       "4  nghệ anhai nhóm thanh_niên ở huyện đô_lương do...   \n",
       "\n",
       "                                   tokenized_content  \\\n",
       "0  làm gì có bình_đẳng thực_sự phụ_nữ vẫn chịu nh...   \n",
       "1  bạn có biết tôi không thích điều gì ở guardiol...   \n",
       "2  paifang motorcycle pfmoto thương_hiệu xe_máy đ...   \n",
       "3  hướng đến việc nâng cao trải_nghiệm sống của c...   \n",
       "4  ngày 11 3 phòng cảnh_sát hình_sự công_an tỉnh ...   \n",
       "\n",
       "                                       combine_token  \n",
       "0  tại_sao phụ_nữ đòi bình_đẳng nhưng bắt đàn_ông...  \n",
       "1  capello guardiola mất nhiều champions_league v...  \n",
       "2  xe ga sang xịn của ông lớn trung_quốc thiết_kế...  \n",
       "3  không_gian mở phong_cách hàn tại gem park hải_...  \n",
       "4  21 thanh_niên hỗn_chiến trong đêm nghệ anhai n...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('processed_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create documents for doc2vec model\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "documents = [TaggedDocument(doc.split(), [i]) for i, doc in enumerate(df['combine_token'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training model doc2vec \n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "d2v_model = Doc2Vec(documents, vector_size=100, window=5, min_count=1, workers=4, epochs=10)\n",
    "d2v_model.build_vocab(documents)\n",
    "d2v_model.train(documents, total_examples=d2v_model.corpus_count, epochs=d2v_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get document vectors\n",
    "doc_vectors = [d2v_model.infer_vector(doc.split()) for i, doc in enumerate(df['combine_token'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: tại_sao phụ_nữ đòi bình_đẳng nhưng bắt đàn_ông làm trụ_cột quy_tắc số 1 của minh_an khi hẹn_hò là đàn_ông phải thanh_toán ít_nhất năm buổi đầu_tiên từ buổi thứ 6 cô có_thể chia_sẻ một phần nhỏ làm gì có bình_đẳng thực_sự phụ_nữ vẫn chịu nhiều bất_công đàn_ông chi nhiều hơn mới công_bằng cô gái ở tp hcm lập_luận cô cho rằng nam_giới có thu_nhập trung_bình cao hơn trong khi phụ_nữ phải đầu_tư nhiều hơn vào ngoại_hình từ trang_điểm váy áo đến làm tóc để đáp_ứng kỳ_vọng xã_hội việc đàn_ông trả tiền cũng là cách thể_hiện sự nghiêm_túc trong mối quan_hệ tiền ở đâu đàn_ông để tâm ở đó cô kết_luận tuy_nhiên nhiều nam_giới không đồng_tình cho rằng chính tư_duy này tạo ra bất_bình_đẳng tuấn_dũng nhân_viên chứng_khoán 31 tuổi ở hà_nội cho biết luôn thanh_toán các buổi hẹn thường rơi vào_khoảng 500 000 đồng mỗi lần nhưng với anh hành_động này đơn_thuần là phép lịch_sự không phải trách_nhiệm của nam_giới điều khiến dũng_bối_rối là những tiêu_chuẩn mâu_thuẫn lần hẹn_hò gần nhất của anh là với một cô gái tốt_nghiệp thạc_sĩ có thu_nhập hơn 30 triệu đồng chưa có nhà_riêng khi tìm người_yêu cô lại đặt ra tiêu_chí bạn trai phải có nhà_riêng thu_nhập cao hơn mình và sau_này là trụ_cột kinh_tế gia_đình bình_đẳng là cả hai phải cùng có trách_nhiệm không_thể đổ lỗi người chồng bất_tài không chí tiến_thủ không phải trụ_cột nếu kinh_tế gia_đình không tốt_dũng nói anh đặt câu hỏi bình_đẳng giới rốt_cuộc là quyền_lợi và nghĩa_vụ chia đều cho tất_cả hay chỉ là sự lựa_chọn có lợi cho một bên chuyên_gia nghiên_cứu về giới tiến_sĩ phạm_quốc_lộc phó tổng_hiệu_trưởng trường wellspring cho biết câu trả_lời cho thắc_mắc của tuấn_dũng nằm ở truyền_thống việc mong_muốn đàn_ông làm trụ_cột gia_đình chỉ là bản_sao lặp lại các giá_trị của chế_độ phụ_quyền chứ không phải phụ_nữ tự nghĩ ra ông lộc nói việt_nam đã đạt nhiều thành_tựu quan_trọng trong bình_đẳng giới hiện đứng thứ 72 146 quốc_gia tăng 11 bậc so với năm 2022 theo báo_cáo khoảng_cách giới toàn_cầu năm 2024 tuy_nhiên nhiều nhà_nghiên_cứu cho rằng xã_hội việt_nam vẫn vận_hành theo cơ_chế phụ_quyền các chuẩn_mực liên_quan đến nam_tính vẫn đang được coi_trọng và trong đó người phụ_nữ bị đẩy vào thế_yếu hơn ví_dụ trong công_việc người ta nói cơ_hội là công_bằng nam_nữ có đầy_đủ năng_lực đều có cơ_hội thăng_tiến như nhau song xã_hội vẫn coi tiêu_chí của một người lãnh_đạo là quyết_đoán cứng_rắn kết giao rộng đây đều là các phẩm_chất gắn liền với nam_giới trong một xã_hội phụ_quyền phụ_nữ rất khó để có một sân_chơi công_bằng như nam_giới tiến_sĩ phạm_quốc_lộc nói chuyên_gia giới lê_quang_bình giám_đốc doanh_nghiệp xã_hội ecue và điều_phối_viên mạng_lưới vgem về bình_đẳng giới cho biết có rất nhiều tranh_luận thời_gian qua xoay quanh mâu_thuẫn phụ_nữ muốn công_bằng nhưng thích được ưu_tiên ví_dụ như nhường chỗ ngồi xếp_hàng bê giúp đồ nặng tuy_nhiên theo ông các hành_vi này phần_nhiều thuộc về văn_hóa ứng_xử và không nên bị nhầm_lẫn với bình_đẳng giới thực_sự khi nhìn vào bình_đẳng giới nếu chỉ nhìn theo kiểu cào_bằng là thiếu đi sự tinh_tế và nhạy_cảm_văn_hóa vấn_đề cốt_lõi là ở thăng_tiến trong công_việc và phân_chia gánh nặng lao_động tại việt_nam phụ_nữ trung_bình dành nhiều hơn nam_giới hai giờ mỗi ngày cho việc nhà và chăm_sóc gia_đình khiến họ có ít thời_gian để phát_triển bản_thân và sự_nghiệp chuẩn_mực giới còn vô_hình_định_hình lộ_trình nghề_nghiệp phụ_nữ bị định_hướng vào các công_việc ổn_định ít rủi_ro hạn_chế khả_năng vươn lên vị_trí lãnh_đạo kết_quả khoảng_cách thu_nhập giữa nam và nữ ở việt_nam vẫn đang cách xa nhau trung_bình lao_động nam nhận 8 7 triệu đồng lao_động nữ là 6 5 triệu đồng một tháng tỷ_lệ nữ_giới trong các vai_trò quản_lý chỉ 28 ngay cả trong những ngành có đông lao_động nữ theotổng_cục thống_kê 2024 trong khi phụ_nữ phải đối_mặt với những bất_lợi do kỳ_vọng xã_hội nam_giới cũng chịu áp_lực từ các vai_trò_giới truyền_thống nhiều đàn_ông muốn vợ độc_lập nhưng vẫn cảm_thấy tự_ti nếu cô ấy kiếm tiền nhiều hơn trong nghiên_cứu nam_giới và nam_tính của viện nghiên_cứu phát_triển xã_hội isds 1 4 nam_giới tham_gia khảo_sát cho biết họ cảm_thấy áp_lực trong cuộc_sống trong đó có hơn 80 cảm_thấy bị áp_lực về tình_trạng tài_chính và gần 70 bị áp_lực về sự_nghiệp ông bình nhấn_mạnh để đạt được bình_đẳng giới thực_sự cần tách_bạch giữa phép lịch_sự trong đời_sống và những bất_bình_đẳng mang tính hệ_thống vấn_đề không nằm ở việc nhường_ghế hay xếp_hàng mà ở sự phân_chia công_việc chăm_sóc gia_đình một_cách công_bằng đặc_biệt là nam_giới phụ_nữ cần có cơ_hội bình_đẳng trong sự_nghiệp nghĩa_là loại_bỏ thiên_kiến_giới trong tuyển_dụng đào_tạo và thăng_tiến nam_giới cũng cần được giải_tỏa áp_lực từ những kỳ_vọng truyền_thống vốn đè nặng lên sức_khỏe tinh_thần của họ bình_đẳng giới không_chỉ là quyền_lợi của phụ_nữ hay trách_nhiệm của nam_giới mà là một cuộc tái_cấu_trúc xã_hội nơi cả hai giới đều được trao cơ_hội phát_triển mà không bị trói_buộc bởi định_kiến ông bình nói ông lộc cho rằng để thay_đổi cần tác_động đồng_bộ từ chính_trị giáo_dục việc_làm đến truyền_thông và đời_sống hàng ngày nhưng quan_trọng nhất phải phản_biện những chân_lý đã ăn sâu trong xã_hội như phụ_nữ có thiên_chức làm vợ làm mẹ hay đàn_ông là trụ_cột gia_đình những quan_niệm này thực_chất chỉ là hệ tư_duy không phải chân_lý và chúng đang duy_trì bất_công chuyên_gia nói dù_vậy tiến_sĩ lộc_lạc_quan rằng xã_hội việt_nam đang có những tiến_bộ rõ nét chẳng_hạn trước_đây hệ phụ_quyền chỉ nhìn_nhận phụ_nữ qua ngoại_hình ngày_nay nhiều phụ_nữ đã chủ_động phá vỡ tiêu_chuẩn đó không ít mô_hình gia_đình hiện_đại đang chứng_minh vai_trò trụ_cột kinh_tế không còn cố_định ở nam_giới và cả người chồng lẫn vợ hạnh_phúc với lựa_chọn đó mười năm kết_hôn chị ngọc hân 33 tuổi quê vĩnh_phúc_hiếm khi nhận được quà của chồng vào những ngày lễ không phải anh vô_tâm mà bởi đã nộp toàn_bộ lương cho vợ hồi đầu chị từng chạnh_lòng bạn_bè khoe chồng tặng túi_xách nước_hoa đưa đi du_lịch còn chị chỉ nhận một lời chúc đơn_giản có những lần tôi thoáng qua suy_nghĩ chẳng phải đàn_ông vẫn nên là trụ_cột kinh_tế chị nói dần_dần chị không còn bận_tâm đến điều đó nữa gần đây chị hân được bổ_nhiệm lên trưởng phòng trong một công_ty có vốn đầu_tư nước_ngoài công_việc bận_rộn nhưng chị không phải lo_lắng chuyện nhà_cửa vì luôn có chồng một viên_chức xã đảm_đương phần_lớn việc nhà và dạy_dỗ con_cái nhìn lại người phụ_nữ khẳng_định đã tìm được cách vận_hành gia_đình phù_hợp bình_đẳng giới không phải là chia đôi mọi thứ mà là tạo cơ_hội công_bằng để mỗi người phát_huy hết tiềm_năng của mình chị nói\n",
      "Vector: [-0.52800965  0.5329656   0.2587716   0.86586213 -0.8065486  -1.3263525\n",
      " -0.36066532  0.96722716 -2.0187376  -1.0484596  -0.45167047 -0.33610106\n",
      "  0.96844774 -0.07800991  1.1105349  -0.93398905  0.17153999  0.12981427\n",
      " -0.19378108 -1.0538108   0.214351    0.20739551  0.37034157  1.8912866\n",
      " -1.6390345  -0.63486576  0.48520863  1.2041693   0.23122267  0.40219927\n",
      " -0.48722264 -0.34581995  0.5031699   0.900697    1.5924684   2.3404198\n",
      "  0.7227293  -0.988207    0.60080427 -0.41150317  1.2383575  -1.014958\n",
      " -0.11357412 -0.5231706   0.11547485  0.5963751   0.39145538  0.6995902\n",
      " -0.50188786 -0.96721077  0.7077821  -2.426154   -0.8595017  -2.5756168\n",
      "  0.05050873 -0.33272934 -0.67611897 -1.1752262  -0.8600547   1.2857454\n",
      " -0.16175751  2.1805658  -0.28299704  0.2660491  -0.9213549   2.145003\n",
      "  0.8232171   1.524426   -1.626235    1.2430139  -1.1171302  -0.01510933\n",
      "  1.1430745  -0.09027563  2.3247416   0.9485243   0.0874771  -0.34496948\n",
      "  0.86537486  0.9145635   0.13848524  0.6748068  -1.1191132   0.07797283\n",
      "  2.011316    0.24192576 -0.13426554 -0.4715223  -0.368158    0.47747713\n",
      " -1.1875093  -1.5975798   0.43666497  0.8361857   0.5734001  -0.8369404\n",
      " -0.12395461  0.9386934   1.0005616   0.25176695]\n"
     ]
    }
   ],
   "source": [
    "# get representation for first document\n",
    "print(f'Document: {df[\"combine_token\"][0]}')\n",
    "print(f'Vector: {doc_vectors[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model.save('doc2vec_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample training with doc2vec vectors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "X = np.array(doc_vectors)\n",
    "y = df['Tag']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a logistic regression classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7724\n"
     ]
    }
   ],
   "source": [
    "# print out to check\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred): .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X = np.array(doc_vectors)\n",
    "y = df['Tag'].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, vectors, labels):\n",
    "        self.vectors = vectors\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.vectors)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        vector = torch.tensor(self.vectors[idx], dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return {\"vector\": vector, \"label\": label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural net \n",
    "class Doc2VecClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, output_dim=2):\n",
    "        super(Doc2VecClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_doc2vec(X_train, X_test, y_train, y_test, input_dim, num_epochs=10):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Create datasets and dataloaders\n",
    "    train_dataset = CustomDataset(X_train, y_train)\n",
    "    test_dataset = CustomDataset(X_test, y_test)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "    # Initialize model, optimizer, and loss\n",
    "    model = Doc2VecClassifier(input_dim=input_dim).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        for batch in train_loader:\n",
    "            vectors = batch[\"vector\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(vectors)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            predicted = torch.argmax(outputs, dim=1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = correct / len(X_train)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            vectors = batch[\"vector\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(vectors)\n",
    "            predicted = torch.argmax(outputs, dim=1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / len(X_test)\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 35.0699, Accuracy: 0.7490\n",
      "Epoch [2/10], Loss: 26.8847, Accuracy: 0.8255\n",
      "Epoch [3/10], Loss: 22.9959, Accuracy: 0.8612\n",
      "Epoch [4/10], Loss: 21.7143, Accuracy: 0.8622\n",
      "Epoch [5/10], Loss: 18.1389, Accuracy: 0.8847\n",
      "Epoch [6/10], Loss: 16.3905, Accuracy: 0.9041\n",
      "Epoch [7/10], Loss: 14.7611, Accuracy: 0.9173\n",
      "Epoch [8/10], Loss: 12.8254, Accuracy: 0.9316\n",
      "Epoch [9/10], Loss: 11.5476, Accuracy: 0.9388\n",
      "Epoch [10/10], Loss: 10.9862, Accuracy: 0.9429\n",
      "Test Accuracy: 0.8252\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(X_train[0])  # Dimension of Doc2Vec vectors (e.g., 100 if that's what you used)\n",
    "nn_model = train_and_evaluate_doc2vec(X_train, X_test, y_train, y_test, input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from underthesea import word_tokenize\n",
    "\n",
    "def predict_content_doc2vec(content, doc2vec_model, classifier, device):\n",
    "    classifier.eval()\n",
    "    tokenized_content = word_tokenize(content.lower())  # Reuse your existing preprocessing\n",
    "    vector_content = d2v_model.infer_vector(tokenized_content)\n",
    "    vector_content = torch.tensor(vector_content, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = classifier(vector_content)\n",
    "        probs = torch.softmax(output, dim=1)\n",
    "        label = torch.argmax(output, dim=1).item()\n",
    "        probability = probs[0][label].item()\n",
    "\n",
    "    return label, probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0, Probability: 0.9805944561958313\n"
     ]
    }
   ],
   "source": [
    "test_content = df['Content'][20]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "label, probability = predict_content_doc2vec(test_content, d2v_model, nn_model, device)\n",
    "print(f'Label: {label}, Probability: {probability}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT and PhoBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['combine_token'].tolist()  # Raw text\n",
    "y = df['Tag'].tolist()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, doc2vec_model, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.doc2vec_model = doc2vec_model\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        # Generate Doc2Vec vector\n",
    "        doc2vec_vector = torch.tensor(self.doc2vec_model.infer_vector(text.split()), dtype=torch.float32)\n",
    "        # Tokenize text for BERT/PhoBERT\n",
    "        encoding = self.tokenizer(text, padding=\"max_length\", truncation=True,\n",
    "                                 max_length=self.max_length, return_tensors=\"pt\")\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n",
    "            \"doc2vec_vector\": doc2vec_vector,\n",
    "            \"label\": torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridBERTModel(nn.Module):\n",
    "    def __init__(self, model_name, doc2vec_dim, hidden_dim=128, output_dim=2):\n",
    "        super(HybridBERTModel, self).__init__()\n",
    "        self.transformer = AutoModel.from_pretrained(model_name)\n",
    "        transformer_dim = self.transformer.config.hidden_size  # 768 for BERT/PhoBERT\n",
    "        self.fc1 = nn.Linear(transformer_dim + doc2vec_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, doc2vec_vector):\n",
    "        # Get transformer output (pooled [CLS] token embedding)\n",
    "        transformer_output = self.transformer(input_ids, attention_mask=attention_mask).pooler_output\n",
    "        # Concatenate with Doc2Vec vector\n",
    "        combined = torch.cat((transformer_output, doc2vec_vector), dim=1)\n",
    "        x = self.fc1(combined)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_and_finetune_bert_phobert(model_name, X_train, X_test, y_train, y_test, doc2vec_model, num_epochs=10):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Initialize tokenizer and datasets\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    train_dataset = HybridDataset(X_train, y_train, tokenizer, doc2vec_model)\n",
    "    test_dataset = HybridDataset(X_test, y_test, tokenizer, doc2vec_model)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "    # Initialize model\n",
    "    doc2vec_dim = doc2vec_model.vector_size  \n",
    "    model = HybridBERTModel(model_name, doc2vec_dim).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=2e-5)  # Lower learning rate for fine-tuning\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training loop (fine-tuning)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        for batch in train_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            doc2vec_vector = batch[\"doc2vec_vector\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask, doc2vec_vector)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            predicted = torch.argmax(outputs, dim=1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = correct / len(X_train)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            doc2vec_vector = batch[\"doc2vec_vector\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask, doc2vec_vector)\n",
    "            predicted = torch.argmax(outputs, dim=1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / len(X_test)\n",
    "    print(f'Model: {model_name} - Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning PhoBERT with Doc2Vec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 39.3671, Accuracy: 0.6714\n",
      "Epoch [2/10], Loss: 24.2895, Accuracy: 0.8551\n",
      "Epoch [3/10], Loss: 12.1547, Accuracy: 0.9347\n",
      "Epoch [4/10], Loss: 5.1996, Accuracy: 0.9816\n",
      "Epoch [5/10], Loss: 5.6766, Accuracy: 0.9643\n",
      "Epoch [6/10], Loss: 1.5362, Accuracy: 0.9959\n",
      "Epoch [7/10], Loss: 1.0686, Accuracy: 0.9969\n",
      "Epoch [8/10], Loss: 0.3488, Accuracy: 1.0000\n",
      "Epoch [9/10], Loss: 0.2234, Accuracy: 1.0000\n",
      "Epoch [10/10], Loss: 0.1657, Accuracy: 1.0000\n",
      "Model: vinai/phobert-base - Test Accuracy: 0.8902\n",
      "Fine-tuning BERT with Doc2Vec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f02bc7ce154e2e8f32a172657a7fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\DELL\\.cache\\huggingface\\hub\\models--bert-base-multilingual-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b50206007d4c64ba7ebf241ad5667c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9c6de410cc4e3b82a8c36fc8032d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b8e7bbb23e4d13b04a07984165ff9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae57f9366d064614952682eb9b7b7587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 38.9397, Accuracy: 0.6469\n",
      "Epoch [2/10], Loss: 29.8767, Accuracy: 0.7918\n",
      "Epoch [3/10], Loss: 23.5162, Accuracy: 0.8449\n",
      "Epoch [4/10], Loss: 18.1567, Accuracy: 0.8929\n",
      "Epoch [5/10], Loss: 14.1527, Accuracy: 0.9143\n",
      "Epoch [6/10], Loss: 9.6077, Accuracy: 0.9541\n",
      "Epoch [7/10], Loss: 5.5233, Accuracy: 0.9735\n",
      "Epoch [8/10], Loss: 4.6263, Accuracy: 0.9796\n",
      "Epoch [9/10], Loss: 3.5472, Accuracy: 0.9867\n",
      "Epoch [10/10], Loss: 7.4912, Accuracy: 0.9592\n",
      "Model: bert-base-multilingual-cased - Test Accuracy: 0.8008\n"
     ]
    }
   ],
   "source": [
    "print(\"Fine-tuning PhoBERT with Doc2Vec...\")\n",
    "phobert_model, phobert_tokenizer = train_and_finetune_bert_phobert(\n",
    "    'vinai/phobert-base', X_train, X_test, y_train, y_test, d2v_model\n",
    ")\n",
    "\n",
    "print(\"Fine-tuning BERT with Doc2Vec...\")\n",
    "bert_model, bert_tokenizer = train_and_finetune_bert_phobert(\n",
    "    'bert-base-multilingual-cased', X_train, X_test, y_train, y_test, d2v_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_content_hybrid(content, doc2vec_model, hybrid_model, tokenizer, device):\n",
    "    hybrid_model.eval()\n",
    "    # Preprocess and tokenize input\n",
    "    tokenized_content = word_tokenize(content)  # Assuming these functions are defined\n",
    "    doc2vec_vector = torch.tensor(doc2vec_model.infer_vector(tokenized_content), \n",
    "                                 dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    encoding = tokenizer(content, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "    input_ids = encoding[\"input_ids\"].to(device)\n",
    "    attention_mask = encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = hybrid_model(input_ids, attention_mask, doc2vec_vector)\n",
    "        probs = torch.softmax(output, dim=1)\n",
    "        label = torch.argmax(output, dim=1).item()\n",
    "        probability = probs[0][label].item()\n",
    "\n",
    "    return label, probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhoBERT Prediction:\n",
      "Label: 0, Probability: 0.9952795505523682\n",
      "BERT Prediction:\n",
      "Label: 0, Probability: 0.984031081199646\n"
     ]
    }
   ],
   "source": [
    "# test_content = df['Content'][0]\n",
    "test_content = \"Trong một sự kiện được tổ chức tại Hà Nội vào ngày 14/3/2025, \" \\\n",
    "               \"VinFast đã chính thức ra mắt dòng xe điện mới với công nghệ tiên tiến...\"\n",
    "\n",
    "print(\"PhoBERT Prediction:\")\n",
    "label, prob = predict_content_hybrid(test_content, d2v_model, phobert_model, phobert_tokenizer, device)\n",
    "print(f'Label: {label}, Probability: {prob}')\n",
    "\n",
    "print(\"BERT Prediction:\")\n",
    "label, prob = predict_content_hybrid(test_content, d2v_model, bert_model, bert_tokenizer, device)\n",
    "print(f'Label: {label}, Probability: {prob}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
